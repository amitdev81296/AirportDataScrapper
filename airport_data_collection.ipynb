{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Wikipedia Pages To Collect Airport Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Scrape basic airport information such as Name, Location, IATA code, IACO code.\n",
    "2. Going to the links provided for each airport and scraping the latitude and longitude information\n",
    "3. After data for airports with IATA codes beginning with a letter has been collected, we store it into the CSV file. This avoids a large amount of data accumulating in the memory.\n",
    "4. Ideally, we can also do this 5 or 6 letters at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SNOyo1ob7ovD",
    "outputId": "a1f85e48-2320-4232-effa-b3af32b5f686",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Installing the required packages\n",
    "!pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u81FRnUf4IIf",
    "outputId": "41508ae5-d9b1-443e-fbdd-ba4fb689188d"
   },
   "outputs": [],
   "source": [
    "# To be executed only if working with Google Collab\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "sbylR-01c3Ff"
   },
   "outputs": [],
   "source": [
    "# Importing required packages, libraries and functions\n",
    "from pprint import pprint\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import requests\n",
    "import sys\n",
    "import re\n",
    "import numpy as np\n",
    "from string import ascii_lowercase, ascii_uppercase\n",
    "import lxml\n",
    "import lxml.html as lh\n",
    "import pandas as pd\n",
    "from unicodedata import normalize\n",
    "import robotexclusionrulesparser\n",
    "from lat_lon_parser import parse as l_parse\n",
    "import re \n",
    "import csv\n",
    "import time\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Za25BSqKc3Fg"
   },
   "outputs": [],
   "source": [
    "# Initializing the base URL for Wikipedia\n",
    "# And the URL string for alphabetical scraping of airports based on IATA codes\n",
    "wiki_start = \"https://en.wikipedia.org\"\n",
    "alpha_template = \"https://en.wikipedia.org/wiki/List_of_airports_by_IATA_code:_{}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "qdYxBOILc3Fg"
   },
   "outputs": [],
   "source": [
    "# Web scraping restrictions on Wikipedia\n",
    "resp = requests.get(\"{}/robots.txt\".format(wiki_start))\n",
    "robots = resp.text\n",
    "rp = robotexclusionrulesparser.RobotFileParserLookalike()\n",
    "\n",
    "## parse the robots file\n",
    "rp.parse(robots)\n",
    "\n",
    "# If the response code == 429 we hit the rate limit. \n",
    "RATE_LIMIT = 429"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "5eqz10O1c3Fg"
   },
   "outputs": [],
   "source": [
    "# Html & nav helper functions\n",
    "\n",
    "def add_airport(one_row):\n",
    "    stupid_dict = {\n",
    "        'Link': wiki_start + one_row[2].find('a').get('href'),\n",
    "        'Name': one_row[2].text,\n",
    "        'IATA': one_row[0].text,\n",
    "        'ICAO': one_row[1].text, 'Location': one_row[3].text,\n",
    "        'Latitude': None,\n",
    "        'Longitude': None\n",
    "    }\n",
    "    return stupid_dict                             \n",
    "                            \n",
    "def safe_get_html(address):\n",
    "    r = requests.get(address)\n",
    "        \n",
    "    return r.status_code, BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "def get_coor_str(html_soup):\n",
    "    lat_str = html_soup.find('span','latitude').text\n",
    "    long_str = html_soup.find('span','longitude').text\n",
    "\n",
    "    return lat_str, long_str\n",
    "    \n",
    "def get_lat_long(html_soup):\n",
    "    lat_str = html_soup.find('span','latitude').text if html_soup.find('span','latitude') else \"0\"\n",
    "    long_str = html_soup.find('span','longitude').text if html_soup.find('span','longitude') else \"0\"\n",
    "    lat_decimal = l_parse(lat_str)\n",
    "    long_decimal = l_parse(long_str)\n",
    "    return lat_decimal, long_decimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "pLnZL9eEc3Fg"
   },
   "outputs": [],
   "source": [
    "# Method to collect info for airports with IATA code beginning with i\n",
    "def collect_data(i):\n",
    "    start = time.time()\n",
    "    url = alpha_template.format(\"_\"+i)\n",
    "    response = requests.get(url)\n",
    "    print(url, response.status_code)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    table_data = soup.find('body').find('table').find('tbody')\n",
    "    table_rows = table_data.find_all(\"tr\")\n",
    "    _ = table_rows.pop(0)\n",
    "\n",
    "    # there are separators every few rows, to denote the first 2 characters of the airport iata code, ie -AA- , -AB- ect\n",
    "    just_airports = [x for x in table_rows if(len(x.find_all('td'))>0)]\n",
    "    air_list = [port.find_all('td') for port in just_airports]\n",
    "\n",
    "    air_page_list  = []\n",
    "    for one_row in air_list:\n",
    "        air_page_list.append(add_airport(one_row))\n",
    "\n",
    "    # now we loop over the list and navigate to the target page to collect the lat/long\n",
    "    problem_pages = []\n",
    "    for air_page in air_page_list:\n",
    "        if \"Airport\" in air_page[\"Link\"]:\n",
    "            if air_page[\"Link\"].find('redlink=1') == -1:\n",
    "                pg_status, testSoup = safe_get_html(air_page[\"Link\"])\n",
    "                if testSoup:\n",
    "                    air_page[\"Latitude\"], air_page[\"Longitude\"] = get_lat_long(testSoup)\n",
    "                else:\n",
    "                    # Setting aside airports with problematic links\n",
    "                    problem_pages.append((air_page, pg_status))\n",
    "                    continue\n",
    "            else:\n",
    "                # Setting aside airports with problematic links\n",
    "                problem_pages.append((air_page, 404))\n",
    "        else:\n",
    "            # Setting aside airports with problematic links\n",
    "            problem_pages.append((air_page, 404))\n",
    "    print(f\"Finished Scraping {len(air_page_list)} Pages, {len(problem_pages)} Pages Unreachable.\")\n",
    "    print(round(time.time() - start, 2), \"s to process {}\".format(i))\n",
    "    return air_page_list, problem_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "cLs5J6pG7_WV"
   },
   "outputs": [],
   "source": [
    "# For plugging in missing values from an external dataset\n",
    "external_dataset_url = \"https://raw.githubusercontent.com/jpatokal/openflights/master/data/airports.dat\"\n",
    "airport_df = pd.read_csv(external_dataset_url, header=None)\n",
    "airport_df.drop(columns=[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yz-VA9t6BUZP",
    "outputId": "00440c8d-0c67-4aac-a6cb-7937e1e7f4c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://en.wikipedia.org/wiki/List_of_airports_by_IATA_code:__A 200\n",
      "Finished Scraping 527 Pages, 98 Pages Unreachable.\n",
      "76.5 s to process A\n",
      "24 Missing Values Filled\n",
      "Writing Collected Data To File...\n",
      "Size of Data Written to File - 4840 bytes.\n",
      "\n",
      "https://en.wikipedia.org/wiki/List_of_airports_by_IATA_code:__B 200\n",
      "Finished Scraping 616 Pages, 130 Pages Unreachable.\n",
      "144.29 s to process B\n",
      "33 Missing Values Filled\n",
      "Writing Collected Data To File...\n",
      "Size of Data Written to File - 5488 bytes.\n",
      "\n",
      "https://en.wikipedia.org/wiki/List_of_airports_by_IATA_code:__C 200\n",
      "Finished Scraping 545 Pages, 102 Pages Unreachable.\n",
      "139.2 s to process C\n",
      "22 Missing Values Filled\n",
      "Writing Collected Data To File...\n",
      "Size of Data Written to File - 4840 bytes.\n",
      "\n",
      "https://en.wikipedia.org/wiki/List_of_airports_by_IATA_code:__D 200\n",
      "Finished Scraping 302 Pages, 79 Pages Unreachable.\n",
      "68.1 s to process D\n",
      "19 Missing Values Filled\n",
      "Writing Collected Data To File...\n",
      "Size of Data Written to File - 2528 bytes.\n",
      "\n",
      "https://en.wikipedia.org/wiki/List_of_airports_by_IATA_code:__E 200\n",
      "Finished Scraping 254 Pages, 65 Pages Unreachable.\n",
      "62.67 s to process E\n",
      "22 Missing Values Filled\n",
      "Writing Collected Data To File...\n",
      "Size of Data Written to File - 2208 bytes.\n",
      "\n",
      "https://en.wikipedia.org/wiki/List_of_airports_by_IATA_code:__F 200\n",
      "Finished Scraping 211 Pages, 46 Pages Unreachable.\n",
      "52.9 s to process F\n",
      "24 Missing Values Filled\n",
      "Writing Collected Data To File...\n",
      "Size of Data Written to File - 1920 bytes.\n",
      "\n",
      "https://en.wikipedia.org/wiki/List_of_airports_by_IATA_code:__G 200\n",
      "Finished Scraping 371 Pages, 81 Pages Unreachable.\n",
      "98.42 s to process G\n",
      "23 Missing Values Filled\n",
      "Writing Collected Data To File...\n",
      "Size of Data Written to File - 3296 bytes.\n",
      "\n",
      "https://en.wikipedia.org/wiki/List_of_airports_by_IATA_code:__H 200\n",
      "Finished Scraping 301 Pages, 64 Pages Unreachable.\n",
      "83.73 s to process H\n",
      "22 Missing Values Filled\n",
      "Writing Collected Data To File...\n",
      "Size of Data Written to File - 2528 bytes.\n",
      "\n",
      "https://en.wikipedia.org/wiki/List_of_airports_by_IATA_code:__I 200\n",
      "Finished Scraping 268 Pages, 76 Pages Unreachable.\n",
      "51.92 s to process I\n",
      "22 Missing Values Filled\n",
      "Writing Collected Data To File...\n",
      "Size of Data Written to File - 2208 bytes.\n",
      "\n",
      "https://en.wikipedia.org/wiki/List_of_airports_by_IATA_code:__J 200\n",
      "Finished Scraping 165 Pages, 27 Pages Unreachable.\n",
      "36.93 s to process J\n",
      "9 Missing Values Filled\n",
      "Writing Collected Data To File...\n",
      "Size of Data Written to File - 1440 bytes.\n",
      "\n",
      "https://en.wikipedia.org/wiki/List_of_airports_by_IATA_code:__K 200\n",
      "Finished Scraping 508 Pages, 151 Pages Unreachable.\n",
      "97.71 s to process K\n",
      "31 Missing Values Filled\n",
      "Writing Collected Data To File...\n",
      "Size of Data Written to File - 4264 bytes.\n",
      "\n",
      "https://en.wikipedia.org/wiki/List_of_airports_by_IATA_code:__L 200\n",
      "Finished Scraping 465 Pages, 110 Pages Unreachable.\n",
      "104.73 s to process L\n",
      "32 Missing Values Filled\n",
      "Writing Collected Data To File...\n",
      "Size of Data Written to File - 4264 bytes.\n",
      "\n",
      "https://en.wikipedia.org/wiki/List_of_airports_by_IATA_code:__M 200\n",
      "Finished Scraping 645 Pages, 151 Pages Unreachable.\n",
      "142.53 s to process M\n",
      "38 Missing Values Filled\n",
      "Writing Collected Data To File...\n",
      "Size of Data Written to File - 5488 bytes.\n",
      "\n",
      "https://en.wikipedia.org/wiki/List_of_airports_by_IATA_code:__N 200\n",
      "Finished Scraping 324 Pages, 111 Pages Unreachable.\n",
      "56.22 s to process N\n",
      "44 Missing Values Filled\n",
      "Writing Collected Data To File...\n",
      "Size of Data Written to File - 2888 bytes.\n",
      "\n",
      "https://en.wikipedia.org/wiki/List_of_airports_by_IATA_code:__O 200\n",
      "Finished Scraping 308 Pages, 78 Pages Unreachable.\n",
      "65.33 s to process O\n",
      "27 Missing Values Filled\n",
      "Writing Collected Data To File...\n",
      "Size of Data Written to File - 2528 bytes.\n",
      "\n",
      "https://en.wikipedia.org/wiki/List_of_airports_by_IATA_code:__P 200\n",
      "Finished Scraping 480 Pages, 109 Pages Unreachable.\n",
      "109.5 s to process P\n",
      "36 Missing Values Filled\n",
      "Writing Collected Data To File...\n",
      "Size of Data Written to File - 4264 bytes.\n",
      "\n",
      "https://en.wikipedia.org/wiki/List_of_airports_by_IATA_code:__Q 200\n",
      "Finished Scraping 20 Pages, 5 Pages Unreachable.\n",
      "3.45 s to process Q\n",
      "4 Missing Values Filled\n",
      "Writing Collected Data To File...\n",
      "Size of Data Written to File - 256 bytes.\n",
      "\n",
      "https://en.wikipedia.org/wiki/List_of_airports_by_IATA_code:__R 200\n",
      "Finished Scraping 335 Pages, 80 Pages Unreachable.\n",
      "70.82 s to process R\n",
      "20 Missing Values Filled\n",
      "Writing Collected Data To File...\n",
      "Size of Data Written to File - 2888 bytes.\n",
      "\n",
      "https://en.wikipedia.org/wiki/List_of_airports_by_IATA_code:__S 200\n",
      "Finished Scraping 619 Pages, 137 Pages Unreachable.\n",
      "141.44 s to process S\n",
      "42 Missing Values Filled\n",
      "Writing Collected Data To File...\n",
      "Size of Data Written to File - 5488 bytes.\n",
      "\n",
      "https://en.wikipedia.org/wiki/List_of_airports_by_IATA_code:__T 200\n",
      "Finished Scraping 503 Pages, 109 Pages Unreachable.\n",
      "112.08 s to process T\n",
      "21 Missing Values Filled\n",
      "Writing Collected Data To File...\n",
      "Size of Data Written to File - 4264 bytes.\n",
      "\n",
      "https://en.wikipedia.org/wiki/List_of_airports_by_IATA_code:__U 200\n",
      "Finished Scraping 200 Pages, 44 Pages Unreachable.\n",
      "47.31 s to process U\n",
      "8 Missing Values Filled\n",
      "Writing Collected Data To File...\n",
      "Size of Data Written to File - 1664 bytes.\n",
      "\n",
      "https://en.wikipedia.org/wiki/List_of_airports_by_IATA_code:__V 200\n",
      "Finished Scraping 182 Pages, 35 Pages Unreachable.\n",
      "48.55 s to process V\n",
      "11 Missing Values Filled\n",
      "Writing Collected Data To File...\n",
      "Size of Data Written to File - 1664 bytes.\n",
      "\n",
      "https://en.wikipedia.org/wiki/List_of_airports_by_IATA_code:__W 200\n",
      "Finished Scraping 234 Pages, 84 Pages Unreachable.\n",
      "48.61 s to process W\n",
      "19 Missing Values Filled\n",
      "Writing Collected Data To File...\n",
      "Size of Data Written to File - 2208 bytes.\n",
      "\n",
      "https://en.wikipedia.org/wiki/List_of_airports_by_IATA_code:__X 200\n",
      "Finished Scraping 93 Pages, 24 Pages Unreachable.\n",
      "21.26 s to process X\n",
      "6 Missing Values Filled\n",
      "Writing Collected Data To File...\n",
      "Size of Data Written to File - 904 bytes.\n",
      "\n",
      "https://en.wikipedia.org/wiki/List_of_airports_by_IATA_code:__Y 200\n",
      "Finished Scraping 455 Pages, 76 Pages Unreachable.\n",
      "103.36 s to process Y\n",
      "23 Missing Values Filled\n",
      "Writing Collected Data To File...\n",
      "Size of Data Written to File - 3752 bytes.\n",
      "\n",
      "https://en.wikipedia.org/wiki/List_of_airports_by_IATA_code:__Z 200\n",
      "Finished Scraping 116 Pages, 22 Pages Unreachable.\n",
      "30.65 s to process Z\n",
      "5 Missing Values Filled\n",
      "Writing Collected Data To File...\n",
      "Size of Data Written to File - 1064 bytes.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Driver Code For Controlled Web Scraping\n",
    "csv_file = \"airports.csv\"\n",
    "if os.path.isfile(csv_file):\n",
    "    os.remove(csv_file)\n",
    "Path(csv_file).touch()\n",
    "\n",
    "# Looping over all alphabets\n",
    "for i in ascii_uppercase:\n",
    "\n",
    "    # Calling method to scraping the data\n",
    "    airports, _ = collect_data(i)\n",
    "    \n",
    "    # Plugging in missing data\n",
    "    count = 0\n",
    "    for airport in airports:\n",
    "        if airport[\"Latitude\"] is None or airport[\"Longitude\"] is None:\n",
    "            iata = airport[\"IATA\"]\n",
    "            lat = airport_df[airport_df[4] == iata][6]\n",
    "            lon = airport_df[airport_df[4] == iata][7]\n",
    "            if len(np.array(lat)) != 0 and len(np.array(lon)) != 0:\n",
    "                count += 1\n",
    "                airport[\"Latitude\"] = np.array(lat)[0]\n",
    "                airport[\"Longitude\"] = np.array(lon)[0]\n",
    "    print(\"{} Missing Values Filled\".format(count))\n",
    "    # Writing the data to a file after every letter\n",
    "    csv_columns = [\"Link\",\"Name\",\"IATA\",\"ICAO\",\"Location\",\"Latitude\",\"Longitude\"]\n",
    "    dict_data = airports\n",
    "    try:\n",
    "        with open(csv_file, mode ='a', encoding=\"utf-8\") as csvfile:\n",
    "            print(\"Writing Collected Data To File...\")\n",
    "            print(\"Size of Data Written to File - {} bytes.\\n\".format(sys.getsizeof(dict_data)))\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=csv_columns,lineterminator='\\n') #delimiter = ',', lineterminator='\\n'\n",
    "            if os.stat(csv_file).st_size == 0: #check size of the file, if file already exists do not write headers when appending each IATA code of airport data \n",
    "                writer.writeheader()\n",
    "            for data in dict_data:\n",
    "                writer.writerow(data)\n",
    "    except IOError:\n",
    "        print(\"I/O error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 16
    },
    "id": "-hapAo2Mq8kI",
    "outputId": "ea3a5600-8f91-4447-d44f-7c10a8cc2bc7"
   },
   "outputs": [],
   "source": [
    "# Uncomment and run this code to download the csv file\n",
    "# To your computer if you are working on Google Collab\n",
    "\n",
    "# from google.colab import files\n",
    "# files.download(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "ip3xSogvOR0b",
    "outputId": "a266006a-f127-478d-d4e9-c5f6fd7ff993",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Link            0\n",
       "Name            0\n",
       "IATA            0\n",
       "ICAO         1347\n",
       "Location        0\n",
       "Latitude     1507\n",
       "Longitude    1507\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some Optional Code To Load Data From\n",
    "# Our Output File\n",
    "import re \n",
    "import pandas as pd \n",
    "airportdata = pd.read_csv(\"airports.csv\")\n",
    "airportdata.isnull().sum()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "avk_airport_collection_an834fork_26Nov2020.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
